"""
video_stream.py
æ‘„åƒå¤´å®æ—¶è§†é¢‘æµï¼š
- æ³¨å†Œï¼šé‡‡é›†å¤šè§’åº¦äººè„¸å›¾åƒ
- å®æ—¶è®¤è¯ï¼šæŒç»­æ£€æµ‹ç”¨æˆ·å¹¶è¿”å›æ£€æµ‹ç»“æœ
"""
import cv2
import os
import time
from datetime import datetime
import face_recognition
import pickle
import numpy as np
from PIL import Image, ImageDraw, ImageFont


# âœ… è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ‘„åƒå¤´
def auto_detect_camera():
    """è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ‘„åƒå¤´ç´¢å¼•"""
    for i in range(5):  # æ£€æµ‹ç´¢å¼• 0-4
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            print(f"âœ… æ‘„åƒå¤´ç´¢å¼•å¯ç”¨: {i}")
            cap.release()
            return i
        cap.release()
    print("âŒ æ²¡æœ‰å¯ç”¨çš„æ‘„åƒå¤´")
    return -1


# âœ… ä¸­æ–‡æ˜¾ç¤ºå‡½æ•°
def put_chinese_text(frame, text, position, font_path="msyh.ttc", font_size=24, color=(0, 255, 0)):
    """åœ¨ OpenCV çª—å£ä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬"""
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)

    try:
        font = ImageFont.truetype(font_path, font_size)
    except IOError:
        print(f"âŒ æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ï¼š{font_path}")
        return frame

    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)


# âœ… ä¿®æ”¹æ‘„åƒå¤´é‡‡é›†å‡½æ•°
def capture_face_motion(save_dir, username, duration=15, fps=5, font_path="msyh.ttc"):
    """ä½¿ç”¨æ‘„åƒå¤´å®æ—¶é‡‡é›†äººè„¸å¤šå¸§"""

    camera_index = auto_detect_camera()  # è‡ªåŠ¨é€‰æ‹©å¯ç”¨æ‘„åƒå¤´
    if camera_index == -1:
        print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨æ‘„åƒå¤´")
        return []

    cap = cv2.VideoCapture(camera_index)

    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return []

    os.makedirs(save_dir, exist_ok=True)

    print("\nğŸ“¸ è¯·ç¼“æ…¢å·¦å³æ™ƒåŠ¨å¤´éƒ¨è¿›è¡Œé‡‡é›†...")
    print(f"â±ï¸ é‡‡é›†æ—¶é—´ï¼š{duration} ç§’ï¼Œæ¯ç§’é‡‡é›† {fps} å¸§")

    img_paths = []
    frame_interval = 1 / fps
    start_time = time.time()
    last_capture_time = start_time
    frame_count = 0

    while time.time() - start_time < duration:
        ret, frame = cap.read()
        if not ret:
            print("âŒ æ— æ³•è¯»å–è§†é¢‘æµ")
            break

        elapsed_time = time.time() - start_time
        progress = (elapsed_time / duration) * 100
        msg = f"è¯·å·¦å³ç¼“æ…¢æ™ƒå¤´é‡‡é›†äººè„¸ä¿¡æ¯: {progress:.1f}%"

        frame = put_chinese_text(frame, msg, (20, 50), font_path=font_path)

        cv2.imshow("äººè„¸é‡‡é›†", frame)

        if time.time() - last_capture_time >= frame_interval:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            img_path = os.path.join(save_dir, f"{username}_{timestamp}_{frame_count}.jpg")
            cv2.imwrite(img_path, frame)
            img_paths.append(img_path)
            print(f"âœ… å·²ä¿å­˜: {img_path}")

            frame_count += 1
            last_capture_time = time.time()

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

    print(f"\nâœ… é‡‡é›†å®Œæˆï¼å…±é‡‡é›† {len(img_paths)} å¼ å›¾ç‰‡")
    return img_paths


# âœ… ä¿®æ”¹æ‘„åƒå¤´è®¤è¯å‡½æ•°ï¼ˆæ”¯æŒä¸­æ–‡æ ‡ç­¾ï¼‰
def recognize_camera(encoding_dir="./encodings", timeout=60, detection_duration=20, font_path="msyh.ttc"):
    """å®æ—¶è®¤è¯ï¼šä»æ‘„åƒå¤´æ£€æµ‹äººè„¸ï¼Œå¹¶æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾"""

    camera_index = auto_detect_camera()  # è‡ªåŠ¨é€‰æ‹©å¯ç”¨æ‘„åƒå¤´
    if camera_index == -1:
        print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨æ‘„åƒå¤´")
        return None

    cap = cv2.VideoCapture(camera_index)

    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return None

    start_time = time.time()
    encodings = load_encodings(encoding_dir)

    if not encodings:
        print("âŒ æ— äººè„¸ç¼–ç æ–‡ä»¶")
        cap.release()
        cv2.destroyAllWindows()
        return None

    # è®¾å®šæ¯æ¬¡æ‘„åƒå¤´å¼€å¯çš„æ—¶é—´æ®µ
    camera_start_time = time.time()
    best_match = None  # æœ€ä½³åŒ¹é…äººè„¸
    best_confidence = 0  # æœ€é«˜ç½®ä¿¡åº¦
    best_name = None  # æœ€ä½³åŒ¹é…çš„åå­—

    # åœ¨ timeout æ—¶é—´å†…ä¸€ç›´è¿›è¡Œæ£€æµ‹
    while time.time() - start_time < timeout:
        # æ£€æµ‹æ—¶é—´æ®µ
        detection_start_time = time.time()

        while time.time() - detection_start_time < detection_duration:
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–è§†é¢‘æµ")
                break

            face_locations = face_recognition.face_locations(frame)
            face_encodings = face_recognition.face_encodings(frame, face_locations)

            if face_encodings:
                for face_encoding, face_location in zip(face_encodings, face_locations):
                    for name, encoding in encodings.items():
                        results = face_recognition.compare_faces([encoding], face_encoding)
                        face_distance = face_recognition.face_distance([encoding], face_encoding)[0]

                        if results[0]:
                            confidence = 1 - face_distance
                            # æ¯”è¾ƒå½“å‰æ£€æµ‹åˆ°çš„ç½®ä¿¡åº¦æ˜¯å¦ä¸ºæœ€é«˜
                            if confidence > best_confidence:
                                best_confidence = confidence
                                best_name = name
                                best_match = face_location

                            msg = f"è¯†åˆ«ä¸­: {name} ({confidence:.2f})"
                            frame = put_chinese_text(frame, msg, (20, 50), font_path=font_path)

            # æ˜¾ç¤ºæ£€æµ‹ä¸­çš„ä¿¡æ¯
            if best_match is not None:
                display_face(frame, best_match, best_name, best_confidence, font_path)

            # åœ¨æ²¡æœ‰æ£€æµ‹åˆ°æœ€ä½³äººè„¸æ—¶ï¼Œæ˜¾ç¤ºâ€œæ£€æµ‹ä¸­â€
            if best_match is None:
                frame = put_chinese_text(frame, "â³ æ£€æµ‹ä¸­...", (20, 50), font_path=font_path)

            cv2.imshow("å®æ—¶è®¤è¯", frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        if best_match is not None and best_confidence > 0:
            print(f"âœ… æ£€æµ‹ç»“æœ: {best_name} ({best_confidence:.2f})")
            cap.release()
            cv2.destroyAllWindows()
            return best_name, best_confidence

        if time.time() - camera_start_time > timeout:
            print(f"â±ï¸ è¶…è¿‡æœ€å¤§æ£€æµ‹æ—¶é—´: {timeout}ç§’ï¼Œè®¤è¯å¤±è´¥")
            cap.release()
            cv2.destroyAllWindows()
            break

    print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„äººè„¸ï¼Œè®¤è¯å¤±è´¥")
    return None


# âœ… åŠ è½½äººè„¸ç¼–ç 
def load_encodings(encoding_dir):
    """åŠ è½½äººè„¸ç¼–ç """
    encodings = {}

    if not os.path.exists(encoding_dir):
        print(f"âŒ ç¼–ç ç›®å½•ä¸å­˜åœ¨ï¼š{encoding_dir}")
        return encodings

    for filename in os.listdir(encoding_dir):
        if filename.endswith(".pkl"):
            name = filename.split(".")[0]
            with open(os.path.join(encoding_dir, filename), "rb") as f:
                encodings[name] = pickle.load(f)

    print(f"âœ… åŠ è½½ {len(encodings)} ä¸ªç¼–ç ")
    return encodings


# âœ… æ˜¾ç¤ºäººè„¸ä¸æ ‡ç­¾ï¼ˆæ”¯æŒä¸­æ–‡æ ‡ç­¾ï¼‰
def display_face(frame, face_location, name, confidence, font_path="msyh.ttc"):
    """åœ¨è§†é¢‘æµä¸­æ˜¾ç¤ºäººè„¸æ¡†å’Œæ ‡ç­¾"""
    top, right, bottom, left = face_location
    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)

    label = f"{name} ({confidence:.2f})"
    frame = put_chinese_text(frame, label, (left, top - 30), font_path=font_path)
    cv2.imshow("å®æ—¶è®¤è¯", frame)